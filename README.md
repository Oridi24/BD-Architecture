#  Practica-KC-BD-Arquitectura  

Este proyecto forma parte del **M√≥dulo de Arquitectura Big Data**, donde trabajamos con diversas tecnolog√≠as del ecosistema **Hadoop** y herramientas asociadas. Implementamos cl√∫steres en **Google Cloud Dataproc**, configuramos **instancias virtuales en Google Compute Engine**, utilizamos **Redes VPC, Cloud Storage** y m√°s.

---

##üìå  Tecnolog√≠as utilizadas  

### 1Ô∏è Google Cloud Dataproc  
Plataforma administrada para la creaci√≥n y gesti√≥n de cl√∫steres **Hadoop** y **Spark** en la nube, permitiendo el procesamiento eficiente de grandes vol√∫menes de datos.  

### 2Ô∏è Hadoop  
Framework base de la arquitectura utilizada. Se encarg√≥ de la distribuci√≥n y procesamiento de datos a gran escala, gestionados a trav√©s de **HDFS (Hadoop Distributed File System)**.  

### 3Ô∏è Hive  
Herramienta que permite ejecutar **consultas SQL** sobre datos almacenados en Hadoop, facilitando el an√°lisis y transformaci√≥n de informaci√≥n mediante su interfaz similar a SQL.  

### 4Ô∏è Elasticsearch  
Base de datos distribuida optimizada para **b√∫squedas r√°pidas y complejas** sobre grandes vol√∫menes de datos. Se utiliz√≥ para almacenar registros de datos y mejorar la eficiencia en la consulta de informaci√≥n.  

### 5Ô∏è Kibana  
Herramienta de **visualizaci√≥n de datos**, conectada a Elasticsearch para la generaci√≥n de gr√°ficos, paneles interactivos y visualizaci√≥n clara de los datos procesados.  

---

## üìå Pasos del Proyecto  

###  1. Creaci√≥n del Cl√∫ster en Google Cloud Dataproc  
Se configur√≥ un **cl√∫ster Dataproc** con nodos **maestros y trabajadores**, permitiendo la ejecuci√≥n de herramientas como **Hadoop** y **Hive**.  

###  2. Configuraci√≥n de Hive y Hadoop  
Nos conectamos al nodo maestro mediante **SSH** para configurar **Hive y Hadoop**, habilitando el almacenamiento distribuido y la ejecuci√≥n de consultas SQL sobre los datos.  

###  3. Implementaci√≥n de Elasticsearch  
Se instal√≥ y configur√≥ **Elasticsearch** en una **VM independiente**, habilitando la indexaci√≥n y b√∫squeda eficiente de datos.  
Se definieron **reglas de firewall** en Google Cloud para permitir tr√°fico en los puertos:  
- **9200** (Elasticsearch)  
- **5601** (Kibana)  

###  4. Conexi√≥n entre Hadoop y Elasticsearch  
Se estableci√≥ la conexi√≥n entre el cl√∫ster **Hadoop** y **Elasticsearch**, permitiendo la carga y consulta eficiente de datos.  
Utilizamos **curl** para insertar documentos en Elasticsearch, asegurando la conectividad mediante reglas de red y configuraciones de firewall.  

###  5. Carga de datos en Elasticsearch  
Se us√≥ la **API de Elasticsearch** para insertar documentos en el √≠ndice **alumnos** desde Hadoop, optimizando la carga masiva de informaci√≥n.  

###  6. Visualizaci√≥n de datos con Kibana  
Finalmente, se configur√≥ **Kibana** para visualizar y explorar los datos almacenados en **Elasticsearch**, permitiendo la creaci√≥n de gr√°ficos y paneles interactivos.  

---

## üìå Conclusi√≥n  

A lo largo de esta pr√°ctica, trabajamos con **Google Cloud Dataproc, Hadoop, Hive, Elasticsearch y Kibana**, construyendo una infraestructura robusta y escalable para el **procesamiento y an√°lisis de datos** en la nube.  

Este proyecto brind√≥ una comprensi√≥n m√°s profunda sobre las **arquitecturas modernas de Big Data**, su integraci√≥n con servicios en la nube y c√≥mo optimizar el flujo de datos para mejorar la eficiencia y escalabilidad. üöÄ  



---------------------------------------------------------------------------------------------------------------------------------------------------


# **Practica-KC-BD-Architecture**
Este proyecto es parte del M√≥dulo de Arquitectura Big Data, donde he trabajado con varias tecnolog√≠as de la arquitectura Hadoop y herramientas asociadas. A lo largo del modulo, he creado diversos cl√∫steres en Google Cloud Dataproc, diversas instancias virtuales de Google Compute Engine, Redes VPC, Cloud Storage y mas.

*Tecnolog√≠as utilizadas:*</p>
_1- Google Cloud Dataproc:_ Utilizamos Google Cloud Dataproc para crear y gestionar un cl√∫ster Hadoop. Dataproc es una plataforma administrada que facilita el trabajo con frameworks como Hadoop y Spark , permiti√©ndonos ejecutar y gestionar grandes vol√∫menes de datos con eficiencia en la nube.

_2- Hadoop:_ Hadoop es la base de esta arquitectura, y se utiliza para distribuir el procesamiento de grandes vol√∫menes de datos. La configuraci√≥n de HDFS (Hadoop Distributed File System) permite almacenar y gestionar los datos de manera distribuida en el cl√∫ster.

_3- Hive:_ Utilizamos Hive para realizar consultas SQL sobre los datos almacenados en Hadoop. Hive proporciona una interfaz similar a SQL para facilitar el an√°lisis de grandes cantidades de datos. Esto nos permiti√≥ ejecutar consultas sobre los datos y realizar transformaciones de manera eficiente.

_4- Elasticsearch:_ Implementamos Elasticsearch para almacenar y buscar datos indexados. Elasticsearch es una base de datos distribuida de b√∫squeda que permite realizar b√∫squedas r√°pidas y complejas sobre grandes vol√∫menes de datos. Fue utilizado para almacenar registros de datos y permitir consultas m√°s r√°pidas y efectivas.

_5- Kibana:_ Usamos Kibana como herramienta de visualizaci√≥n de datos para interactuar con Elasticsearch. Kibana se conecta a Elasticsearch para crear gr√°ficos y paneles din√°micos que permiten una visualizaci√≥n clara y comprensible de los datos procesados ‚Äã‚Äãy almacenados.

<b>*Pasos del Proyecto:*</b>
1. Creaci√≥n del Cl√∫ster en Google Cloud Dataproc
Iniciamos creando un cl√∫ster Dataproc en Google Cloud.Este cl√∫ster incluye los nodos maestros y trabajadores necesarios para ejecutar aplicaciones Hadoop, como Hive y otros componentes de procesamiento de datos.

2. Configuraci√≥n de Hive y Hadoop en el Cl√∫ster
Una vez creado el cl√∫ster, onectamos a trav√©s de SSH a la VM del nodo maestro y configuramos Hive y Hadoop. Con esto, habilitamos el procesamiento y almacenamiento de grandes vol√∫menes de datos, facilitando el an√°lisis mediante consultas SQL.

3. Implementaci√≥n de Elasticsearch
Luego, instalamos y configuramos Elasticsearch en una VM adicional para almacenar los datos procesados ‚Äã‚Äãy permitir b√∫squedas eficientes.Para ello, configuramos las reglas de firewall en Google Cloud para permitir el tr√°fico hacia el puerto 9200 de la VM que ejecuta Elasticsearch y 5601 que ejecuta Kibana.

4. Conexi√≥n entre Hadoop y Elasticsearch
Configuramos la conexi√≥n entre el cl√∫ster de Hadoop y Elasticsearch para poder cargar y procesar los datos de manera eficiente. Utilizamos curl para agregar documentos al √≠ndice de Elasticsearch y aseguramos que las conexiones entre las instancias fueran posibles mediante el ajuste de las configuraciones de red y las reglas de firewall.

5. Carga de datos en Elasticsearch
Usamos la herramienta API de Elasticsearch para cargar documentos de datos en el √≠ndice alumnos desde el cl√∫ster de Hadoop. Esto nos permiti√≥ insertar varios documentos a la vez de manera eficiente.

6. Visualizaci√≥n de datos con Kibana
Una vez que los datos fueron cargados y almacenados en Elasticsearch, configuramos Kibana para visualizar y explorar los datos de manera interactiva. Kibana se conecta a Elasticsearch y permite crear paneles y gr√°ficos que visualizan los datos de manera clara.

_<p>.**Conclusi√≥n**.</p>_
A lo largo de esta pr√°ctica, he trabajado con Google Cloud Dataproc, Hadoop, Hive, Elasticsearch y Kibana, creando una infraestructura robusta y escalable para el procesamiento y an√°lisis de grandes vol√∫menes de datos. Este flujo de trabajo me ha proporcionado una comprensi√≥n m√°s profunda de c√≥mo las arquitecturas modernas de Big Data funcionan en la nube y c√≥mo integran herramientas para maximizar la eficiencia y la facilidad de uso.
