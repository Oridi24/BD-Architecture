# *Big Data Architecture*
*Este proyecto es parte del M√≥dulo de ***Arquitectura Big Data***, donde he trabajado con varias tecnolog√≠as de la arquitectura Hadoop y herramientas asociadas. A lo largo del modulo, he creado diversos cl√∫steres en ***Google Cloud Dataproc, diversas instancias virtuales de Google Compute Engine, Redes VPC, Cloud Storage y mas***.*

> *"Deploy, scale, repeat. En la nube, los sue√±os y los datos no tienen l√≠mite."*

## üìå *Objetivos del Proyecto*

-  ***Dise√±ar y desplegar una arquitectura Big Data completa en la nube***, *usando servicios gestionados y configuraciones manuales sobre Google Cloud Platform (GCP).*
-  ***Implementar un cl√∫ster Hadoop funcional*** *mediante Dataproc, incluyendo nodos maestros y trabajadores.*
-  ****Realizar consultas SQL sobre grandes vol√∫menes de datos*** utilizando Hive como interfaz accesible para an√°lisis.*
-  **Almacenar e indexar datos de forma distribuida*** mediante *Elasticsearch, habilitando b√∫squedas complejas y r√°pidas.*
- ***Visualizar los datos de manera din√°mica y comprensible*** *con Kibana, creando dashboards interactivos conectados a los √≠ndices de Elasticsearch.*
-  ***Establecer conexiones entre servicios distribuidos*** *en diferentes instancias virtuales, configurando reglas de red, firewalls y comunicaci√≥n entre nodos de manera segura y eficiente.*
-  ***Adquirir experiencia pr√°ctica en despliegue cloud de soluciones Big Data***, *aplicando conceptos clave de escalabilidad, disponibilidad y rendimiento.*

---

## ‚öôÔ∏è *Tecnolog√≠as utilizadas:*

1- ****Google Cloud Dataproc***: Utilizamos Google Cloud Dataproc para crear y gestionar un cl√∫ster Hadoop. Dataproc es una plataforma administrada que facilita el trabajo con frameworks como Hadoop y Spark , permiti√©ndonos ejecutar y gestionar grandes vol√∫menes de datos con eficiencia en la nube.*

2- ****Hadoop:*** Hadoop es la base de esta arquitectura, y se utiliza para distribuir el procesamiento de grandes vol√∫menes de datos. La configuraci√≥n de HDFS (Hadoop Distributed File System) permite almacenar y gestionar los datos de manera distribuida en el cl√∫ster*.

3- ****Hive***: Utilizamos Hive para realizar consultas SQL sobre los datos almacenados en Hadoop. Hive proporciona una interfaz similar a SQL para facilitar el an√°lisis de grandes cantidades de datos. Esto nos permiti√≥ ejecutar consultas sobre los datos y realizar transformaciones de manera eficiente.*

4- ****Elasticsearch***: Implementamos Elasticsearch para almacenar y buscar datos indexados. Elasticsearch es una base de datos distribuida de b√∫squeda que permite realizar b√∫squedas r√°pidas y complejas sobre grandes vol√∫menes de datos. Fue utilizado para almacenar registros de datos y permitir consultas m√°s r√°pidas y efectivas.*

5-****Kibana:*** Usamos Kibana como herramienta de visualizaci√≥n de datos para interactuar con Elasticsearch. Kibana se conecta a Elasticsearch para crear gr√°ficos y paneles din√°micos que permiten una visualizaci√≥n clara y comprensible de los datos procesados ‚Äã‚Äãy almacenados.*

---


## üîç *Pasos del Proyecto:*

 1. ***Creaci√≥n del Cl√∫ster en Google Cloud Dataproc***: *Iniciamos creando un cl√∫ster Dataproc en Google Cloud.Este cl√∫ster incluye los nodos maestros y trabajadores necesarios para ejecutar aplicaciones Hadoop, como Hive y otros componentes de procesamiento de datos*.

 2. ***Configuraci√≥n de Hive y Hadoop en el Cl√∫ster***: *Una vez creado el cl√∫ster, onectamos a trav√©s de SSH a la VM del nodo maestro y configuramos Hive y Hadoop. Con esto, habilitamos el procesamiento y almacenamiento de grandes vol√∫menes de datos, facilitando el an√°lisis mediante consultas SQL.*

3. ***Implementaci√≥n de Elasticsearch***: *Luego, instalamos y configuramos Elasticsearch en una VM adicional para almacenar los datos procesados ‚Äã‚Äãy permitir b√∫squedas eficientes.Para ello, configuramos las reglas de firewall en Google Cloud para permitir el tr√°fico hacia el puerto 9200 de la VM que ejecuta Elasticsearch y 5601 que ejecuta Kibana.*

4. ***Conexi√≥n entre Hadoop y Elasticsearch***: *Configuramos la conexi√≥n entre el cl√∫ster de Hadoop y Elasticsearch para poder cargar y procesar los datos de manera eficiente. Utilizamos curl para agregar documentos al √≠ndice de Elasticsearch y aseguramos que las conexiones entre las instancias fueran posibles mediante el ajuste de las configuraciones de red y las reglas de firewall.*

5. ***Carga de datos en Elasticsearch***:*Usamos la herramienta API de Elasticsearch para cargar documentos de datos en el √≠ndice alumnos desde el cl√∫ster de Hadoop. Esto nos permiti√≥ insertar varios documentos a la vez de manera eficiente.*

6. ***Visualizaci√≥n de datos con Kibana***: *Una vez que los datos fueron cargados y almacenados en Elasticsearch, configuramos Kibana para visualizar y explorar los datos de manera interactiva. Kibana se conecta a Elasticsearch y permite crear paneles y gr√°ficos que visualizan los datos de manera clara.*
   

## üëâ *Conclusi√≥n* 
*A lo largo de esta pr√°ctica, he trabajado con ***Google Cloud Dataproc, Hadoop, Hive, Elasticsearch y Kibana***, creando una infraestructura robusta y escalable para el procesamiento y an√°lisis de grandes vol√∫menes de datos.*
*Este flujo de trabajo me ha proporcionado una comprensi√≥n m√°s profunda de c√≥mo las arquitecturas modernas de Big Data funcionan en la nube y c√≥mo integran herramientas para maximizar la eficiencia y la facilidad de uso.*
